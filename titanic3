import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from catboost import CatBoostClassifier
from lightgbm import LGBMClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import pickle

titanic_data = pd.read_csv('https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv')

print(titanic_data.head())

X = titanic_data.drop('Survived', axis=1)  # Features
y = titanic_data['Survived']  # Target variable

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

categorical_features = ['Pclass', 'Sex', 'Embarked']
numerical_features = ['Age', 'SibSp', 'Parch', 'Fare']

preprocessor = ColumnTransformer(
    transformers=[
        ('num', SimpleImputer(strategy='mean'), numerical_features),
        ('cat', Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='most_frequent')),
            ('onehot', OneHotEncoder(handle_unknown='ignore'))
        ]), categorical_features)
    ])

catboost_model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', CatBoostClassifier(random_state=42, verbose=False))
])

lgbm_model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', LGBMClassifier(random_state=42))
])

catboost_param_grid = {
    'classifier__iterations': [50, 100, 200],
    'classifier__depth': [3, 5, 7],
    'classifier__learning_rate': [0.01, 0.1, 0.2]
}

lgbm_param_grid = {
    'classifier__n_estimators': [50, 100, 200],
    'classifier__max_depth': [3, 5, 7],
    'classifier__learning_rate': [0.01, 0.1, 0.2]
}

catboost_grid_search = GridSearchCV(catboost_model, param_grid=catboost_param_grid, cv=5, scoring='accuracy', verbose=2, n_jobs=-1)
lgbm_grid_search = GridSearchCV(lgbm_model, param_grid=lgbm_param_grid, cv=5, scoring='accuracy', verbose=2, n_jobs=-1)

catboost_grid_search.fit(X_train, y_train)
lgbm_grid_search.fit(X_train, y_train)

print("CatBoost Best Parameters:", catboost_grid_search.best_params_)
print("LGBM Best Parameters:", lgbm_grid_search.best_params_)

catboost_y_pred = catboost_grid_search.predict(X_test)
lgbm_y_pred = lgbm_grid_search.predict(X_test)

print("CatBoost Accuracy:", accuracy_score(y_test, catboost_y_pred))
print("\nCatBoost Classification Report:\n", classification_report(y_test, catboost_y_pred))
print("\nCatBoost Confusion Matrix:\n", confusion_matrix(y_test, catboost_y_pred))

print("LGBM Accuracy:", accuracy_score(y_test, lgbm_y_pred))
print("\nLGBM Classification Report:\n", classification_report(y_test, lgbm_y_pred))
print("\nLGBM Confusion Matrix:\n", confusion_matrix(y_test, lgbm_y_pred))

with open('best_catboost_titanic_model.pkl', 'wb') as catboost_model_file:
    pickle.dump(catboost_grid_search.best_estimator_, catboost_model_file)

with open('best_lgbm_titanic_model.pkl', 'wb') as lgbm_model_file:
    pickle.dump(lgbm_grid_search.best_estimator_, lgbm_model_file)

